{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3472fbc-c21f-43fe-ab1d-43ebb9638ec1",
   "metadata": {},
   "source": [
    "# Setting up the analysis\n",
    "\n",
    "## Getting the data on the sample firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7350f40e-0f3a-41b0-8dcd-da721c4863c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "from sec_edgar_downloader import Downloader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import zipfile\n",
    "import fnmatch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"It looks like you're parsing an XML document using an HTML parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9888d49-c6e6-4a1c-b1df-ef81428eb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# places to put files - best practice chapter 2!\n",
    "\n",
    "os.makedirs(\"inputs\", exist_ok=True)\n",
    "os.makedirs(\"10k_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78b590-2ba3-4faa-b71c-df3fcf4bed5e",
   "metadata": {},
   "source": [
    "## Step 1: Get the URL to the S&P 500 firms\n",
    "\n",
    "Using a sample of S&P500 firms is sensible. Two major points come up, the first of which we discussed in class a lot.\n",
    "\n",
    "The obvious limitation is \"what if the relationships between our risk measurements and returns during a pandemic are different for smaller firms outside the S&P500\"? This is a good concern, and worthy of discussion in your results. Do you have an **economic argument** for why your particular risks would be more or less relevant in a pandemic for small firms (than for the larger firms in the S&P500)? Depending on your answer, that means a relationship you find might be too high or too low. Maybe the sign of the relationship flips. \n",
    "\n",
    "The second major issue how we get the list of S&P 500 firms below. This code gets the list of S&P 500 firms **as of today.** So our sample (A) excludes firms that were S&P in Mar 2020 but no longer are and (B) includes firms that weren't before but are now.  This could bias our results. \n",
    "- Perhaps the firms we are erroneously missing (which we know had poor returns) had HIGH risk factors (which is why they did poorly). So excluding them makes it harder to find a risk-return relationship. \n",
    "- Perhaps the firms that we are erroneously including (with high returns) had low risk factors (which is why they fared better in the pandemic). So including them makes it easier to find a risk-return relationship. \n",
    "\n",
    "Putting those arguments together, the very way I constructed this sample might bias the results, but it depends on the specifics of the \"leavers\" and \"joiners\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c466d4d9-4900-4c27-bbdb-e9a4064fca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a file with sample firms and info on them\n",
    "# (somewhat simplistic option!)\n",
    "\n",
    "sp500_file = 'inputs/sp500_2022.csv'\n",
    "\n",
    "if not os.path.exists(sp500_file):\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    pd.read_html(url)[0].to_csv(sp500_file,index=False)\n",
    "\n",
    "sp500 = pd.read_csv('inputs/sp500_2022.csv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb2cc64-26e4-4abf-9d34-c916b09d8892",
   "metadata": {},
   "source": [
    "## Step 2: Download their last 10-K before the pandemic started\n",
    "\n",
    "This took 4 seconds per download. \n",
    "\n",
    "In total: ~42 minutes, and downloaded a 10-K for X of the 503 firms.\n",
    "\n",
    "This code here does not attempt to fix or explore why X 10-Ks are missing. Do you know why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6c7e92-b838-4676-8b3d-60817cb33447",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = Downloader(\"10k_files\") # all files will go within this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec6ccd0-8baa-49aa-ac9e-e1fc15b08b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:15<00:00,  3.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# First, check what files we already have in the ZIP folder \n",
    "# We will use this in the next block to avoid downloading duplicates\n",
    "zip_folder_name = '10k_files/10k_files.zip'\n",
    "if os.path.exists(zip_folder_name):\n",
    "    with zipfile.ZipFile(zip_folder_name, 'r') as zip:\n",
    "        # Get a list of all the files in the ZIP folder using the namelist() method\n",
    "        file_list = zip.namelist()\n",
    "else:\n",
    "    file_list = []\n",
    "    \n",
    "# Append new files to the existing ZIP folder\n",
    "with zipfile.ZipFile(zip_folder_name, 'a',zipfile.ZIP_DEFLATED) as zip:\n",
    "\n",
    "    # Loop over a subset of firms\n",
    "    for firm in tqdm(sp500['Symbol'][:20]):\n",
    "\n",
    "        # look in the file_list (from the existing list) for files from this firm\n",
    "        # note: first folder level inside the zip is sec-edgar-filings\n",
    "        pattern = 'sec-edgar-filings/'+firm+'/10-K/*/*.html'\n",
    "        firm_files = fnmatch.filter(file_list, pattern)  # Check if any matching file already exists\n",
    "        \n",
    "        # If we haven't downloaded any HTML files for this firm, do so        \n",
    "        if len(firm_files) == 0:  \n",
    "            dl.get(\"10-K\", firm, amount=1, after=\"2022-01-01\", before=\"2022-12-31\")\n",
    "\n",
    "        # put a pause here to be nice to server \n",
    "        # NVM: not needed! sec_edgar_downloader automatically limits speed \n",
    "\n",
    "        # Add any new HTML files to the ZIP folder and delete them from the local folder\n",
    "        for f in glob.glob('10K_files/sec-edgar-filings/'+firm+'/10-K/*/*'):\n",
    "            \n",
    "            # note: to match the output of ZIPAFTER, save this to the zip folder\n",
    "            # with a filepath that starts at sec-edgar-filings\n",
    "            # this is hacky and I wouldnt do this EXCEPT I want both routes to have same \n",
    "            # intermediate zip structures so future lessons work no matter which route you \n",
    "            # choose\n",
    "            zip_f = f[10:]\n",
    "            \n",
    "            if zip_f.endswith('.html') and not zip_f in file_list:  \n",
    "                zip.write(f,zip_f)  \n",
    "            os.remove(f)  # Delete the file from the local folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "438d2964-0b6b-45f9-a914-023f87d48fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('10K_files/sec-edgar-filings/'+firm+'/10-K/*/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936defc5-c290-473c-bfe5-b4476147b495",
   "metadata": {},
   "source": [
    "## Unnecessary cleaning up step\n",
    "\n",
    "The `10k_files` folder _should_ be a tree of folders with no files in it. You can check that in your OS easily and manually delete if so. But this will do it automatically for you. After running this, if there are any folders left, that means you have files inside it somewhere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c096733-fa8f-4451-8e7a-d3ed519d1a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_empty_directories(path):\n",
    "    # Loop over all files and directories in the current directory\n",
    "    for entry in os.listdir(path):\n",
    "        full_path = os.path.join(path, entry)\n",
    "\n",
    "        # If the entry is a directory, recurse into it\n",
    "        if os.path.isdir(full_path):\n",
    "            delete_empty_directories(full_path)\n",
    "\n",
    "            # If the directory is empty after deleting subdirectories, delete it\n",
    "            if not os.listdir(full_path):\n",
    "                os.rmdir(full_path)\n",
    "\n",
    "# call the recursive function to delete empty directories inside the directory\n",
    "delete_empty_directories('10k_files')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
