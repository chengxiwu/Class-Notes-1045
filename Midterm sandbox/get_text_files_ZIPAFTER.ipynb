{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3472fbc-c21f-43fe-ab1d-43ebb9638ec1",
   "metadata": {},
   "source": [
    "# Setting up the analysis\n",
    "\n",
    "## Getting the data on the sample firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7350f40e-0f3a-41b0-8dcd-da721c4863c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "from sec_edgar_downloader import Downloader\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"It looks like you're parsing an XML document using an HTML parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9888d49-c6e6-4a1c-b1df-ef81428eb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# places to put files - best practice chapter 2!\n",
    "\n",
    "os.makedirs(\"inputs\", exist_ok=True)\n",
    "os.makedirs(\"10k_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78b590-2ba3-4faa-b71c-df3fcf4bed5e",
   "metadata": {},
   "source": [
    "## Step 1: Get the URL to the S&P 500 firms\n",
    "\n",
    "Using a sample of S&P500 firms is sensible. Two major points come up, the first of which we discussed in class a lot.\n",
    "\n",
    "The obvious limitation is \"what if the relationships between our risk measurements and returns during a pandemic are different for smaller firms outside the S&P500\"? This is a good concern, and worthy of discussion in your results. Do you have an **economic argument** for why your particular risks would be more or less relevant in a pandemic for small firms (than for the larger firms in the S&P500)? Depending on your answer, that means a relationship you find might be too high or too low. Maybe the sign of the relationship flips. \n",
    "\n",
    "The second major issue how we get the list of S&P 500 firms below. This code gets the list of S&P 500 firms **as of today.** So our sample (A) excludes firms that were S&P in Mar 2020 but no longer are and (B) includes firms that weren't before but are now.  This could bias our results. \n",
    "- Perhaps the firms we are erroneously missing (which we know had poor returns) had HIGH risk factors (which is why they did poorly). So excluding them makes it harder to find a risk-return relationship. \n",
    "- Perhaps the firms that we are erroneously including (with high returns) had low risk factors (which is why they fared better in the pandemic). So including them makes it easier to find a risk-return relationship. \n",
    "\n",
    "Putting those arguments together, the very way I constructed this sample might bias the results, but it depends on the specifics of the \"leavers\" and \"joiners\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c466d4d9-4900-4c27-bbdb-e9a4064fca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a file with sample firms and info on them\n",
    "# (somewhat simplistic option!)\n",
    "\n",
    "sp500_file = 'inputs/sp500_2022.csv'\n",
    "\n",
    "if not os.path.exists(sp500_file):\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    pd.read_html(url)[0].to_csv(sp500_file,index=False)\n",
    "\n",
    "sp500 = pd.read_csv('inputs/sp500_2022.csv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb2cc64-26e4-4abf-9d34-c916b09d8892",
   "metadata": {},
   "source": [
    "## Step 2: Download their last 10-K before the pandemic started\n",
    "\n",
    "This took 4 seconds per download. \n",
    "\n",
    "In total: ~42 minutes, and downloaded a 10-K for X of the 503 firms.\n",
    "\n",
    "This code here does not attempt to fix or explore why X 10-Ks are missing. Do you know why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6c7e92-b838-4676-8b3d-60817cb33447",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = Downloader(\"10k_files\") # all files will go within this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec6ccd0-8baa-49aa-ac9e-e1fc15b08b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:12<00:00,  3.63s/it]\n"
     ]
    }
   ],
   "source": [
    "# assumption: if we have a zip file, it means we are done with downloads\n",
    "# so don't download anything\n",
    "\n",
    "if not os.path.exists('10k_files/10k_files.zip'):\n",
    "\n",
    "    for firm in tqdm(sp500['Symbol'][:20]):\n",
    "\n",
    "        firm_folder = \"10k_files/sec-edgar-filings/\" + firm\n",
    "\n",
    "        # if I haven't downloaded an HTML for this firm, do so\n",
    "        if len(glob.glob(firm_folder + '/10-K/*/*.html')) == 0:\n",
    "            dl.get(\"10-K\", firm, amount=1, after=\"2022-01-01\", before=\"2022-12-31\")\n",
    "\n",
    "        # pause - be nice to server \n",
    "        # NVM: not needed! sec_edgar_downloader automatically limits speed \n",
    "\n",
    "        # we don't need the .txt files. If there is one for this firm, delete it\n",
    "        for txt_f in glob.glob(firm_folder + '/10-K/*/*.txt'):\n",
    "            os.remove(txt_f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de8e783-a3ff-436f-be90-71f5d889debf",
   "metadata": {},
   "source": [
    "## Step 3: Reduce the hard drive space \n",
    "\n",
    "_Note: I've made some choices below to ensure the resulting structure is the same as we get from our \"ZIPDURING\" route. As always, there are multiple ways to achieve the same thing. This is one way._\n",
    "\n",
    "Don't run this until you are done with downloads. What is below is a \"one shot\" code. Use it once only. I made this choice explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22a884f3-ff7a-4fa2-8e53-1434491431cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to True to run the code below. make sure you are done with downloads first!\n",
    "# see if your folder has ~500ish html files, and take the screenshot from instructions\n",
    "done_with_downloads = False \n",
    "\n",
    "if os.path.exists('10k_files/sec-edgar-filings') and \\\n",
    "    not os.path.exists('10k_files/10k_files.zip') and \\\n",
    "    done_with_downloads:\n",
    "    \n",
    "    # zip the folder (15GB --> 3GB)\n",
    "    shutil.make_archive('10k_files', 'zip', '10k_files')\n",
    "    \n",
    "    # delete the folder \n",
    "    shutil.rmtree('10k_files/sec-edgar-filings')\n",
    "    \n",
    "    # put the zip file in the `10k_files` folder\n",
    "    shutil.move('10k_files.zip', '10k_files/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
